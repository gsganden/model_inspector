{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "! [ -e /content ] && pip install -Uqq model_inspector\n",
    "# For colab. Restart the runtime after running this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-borough",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'waterfall_chart'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ebebb87af905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwaterfall_chart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_inspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'waterfall_chart'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from functools import partial, update_wrapper\n",
    "from typing import Iterable, Optional, Sequence, Union\n",
    "import warnings\n",
    "\n",
    "from IPython.display import HTML\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.base import ClassifierMixin, clone, RegressorMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import waterfall_chart\n",
    "\n",
    "from model_inspector.explore import plot_correlation\n",
    "from model_inspector.tune import calculate_metrics_by_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-retention",
   "metadata": {},
   "source": [
    "# inspect\n",
    "\n",
    "> Inspect models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Meant to be colorblind-friendly\n",
    "COLORS = {\"blue\": \"#377eb8\", \"orange\": \"#ff7f00\", \"green\": \"#4daf4a\", \"pink\": \"#f781bf\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def Inspector(model, X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"Model inspector\n",
    "\n",
    "    Parameters:\n",
    "    - `model`: Fitted sklearn model\n",
    "    - `X`: Feature matrix with same shape and column meanings as\n",
    "    features `model` was trained on\n",
    "    - `y`: Target series with same length as `X` and same meaning as\n",
    "    target `model` was trained on\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"coef_\") and hasattr(model, \"intercept_\"):\n",
    "        if isinstance(model, RegressorMixin):\n",
    "            result = _LinRegInspector(model, X, y)\n",
    "        elif isinstance(model, ClassifierMixin):\n",
    "            result = _LogRegInspector(model, X, y)\n",
    "    else:\n",
    "        result = _Inspector(model, X, y)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _Inspector:\n",
    "    def __init__(self, model, X, y):\n",
    "        check_is_fitted(model)\n",
    "\n",
    "        self.model, self.X, self.y = model, X, y\n",
    "\n",
    "        self.plot_correlation = partial(\n",
    "            plot_correlation, pd.concat((self.X, self.y), axis=\"columns\")\n",
    "        )\n",
    "        update_wrapper(self.plot_correlation, plot_correlation)\n",
    "\n",
    "        is_binary = (\n",
    "            isinstance(self.model, ClassifierMixin) and len(self.y.unique()) == 2\n",
    "        )\n",
    "        if is_binary:\n",
    "            self.calculate_metrics_by_thresh = partial(\n",
    "                calculate_metrics_by_thresh, self.y, model.predict_proba(self.X)\n",
    "            )\n",
    "            update_wrapper(\n",
    "                self.calculate_metrics_by_thresh, calculate_metrics_by_thresh\n",
    "            )\n",
    "\n",
    "        if len(X.columns) == 1:\n",
    "            if is_binary:\n",
    "                self.plot = partial(_plot1_bin, self)\n",
    "                update_wrapper(self.plot, _plot1_bin)\n",
    "            else:\n",
    "                self.plot = partial(_plot1, self)\n",
    "                update_wrapper(self.plot, _plot1)\n",
    "        if len(X.columns) == 2:\n",
    "            if isinstance(self.model, ClassifierMixin):\n",
    "                self.plot = partial(_plot2_clas, self)\n",
    "                update_wrapper(self.plot, _plot2_clas)\n",
    "                if is_binary:\n",
    "                    self.plot3d = partial(_plot3d_bin, self)\n",
    "                    update_wrapper(self.plot3d, _plot3d_bin)\n",
    "                else:\n",
    "                    self.plot3d = partial(_plot3d_multiclass, self)\n",
    "                    update_wrapper(self.plot3d, _plot3d_multiclass)\n",
    "            else:\n",
    "                self.plot = partial(_plot2_regression, self)\n",
    "                update_wrapper(self.plot, _plot2_regression)\n",
    "                self.plot3d = partial(_plot3d_regression, self)\n",
    "                update_wrapper(self.plot3d, _plot3d_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _LinearInspector(_Inspector):\n",
    "    def __init__(self, model, X, y):\n",
    "        super().__init__(model, X, y)\n",
    "        if isinstance(self.model, ClassifierMixin) and len(self.y.unique()) == 2:\n",
    "            self.plot_waterfall = partial(_plot_waterfall_bin, self)\n",
    "            update_wrapper(self.plot_waterfall, _plot_waterfall_bin)\n",
    "\n",
    "    def show_equation(*args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def plot_coefs_vs_hparam(*args, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _LinRegInspector(_LinearInspector):\n",
    "    \"\"\"Linear regression model inspector\"\"\"\n",
    "\n",
    "    def plot_coefs_vs_hparam(self, hparam: str, vals: Sequence[float]):\n",
    "        \"\"\"Plot coefficient values against a hyperparameter\n",
    "\n",
    "        Parameters:\n",
    "        - `hparam`: Name of hyperparameter; must be an attribute of\n",
    "        `self.model`\n",
    "        - `vals`: Values of that hyperparameter to use\n",
    "        \"\"\"\n",
    "        current_val = getattr(self.model, hparam)\n",
    "        model = clone(self.model)\n",
    "        setattr(model, hparam, vals[-1])\n",
    "        model.fit(self.X, self.y)\n",
    "        column_order = model.coef_.argsort()[::-1]\n",
    "        X = self.X.iloc[:, column_order]\n",
    "\n",
    "        coefs = []\n",
    "        for val in vals:\n",
    "            setattr(model, hparam, val)\n",
    "            coefs.append(model.fit(X, self.y).coef_)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(vals, coefs)\n",
    "        ax.axvline(current_val, c=\"k\", label=\"current value\")\n",
    "        ax.set(xlabel=hparam, ylabel=\"coefficient value\")\n",
    "        ax.legend(X.columns, bbox_to_anchor=(1.05, 1.0), loc=\"upper left\")\n",
    "        return ax\n",
    "\n",
    "    def plot_waterfall(\n",
    "        self,\n",
    "        item: Union[pd.Series, np.array],\n",
    "        bar_num_formatter: str = \".1f\",\n",
    "        tick_num_formatter: str = \".2f\",\n",
    "        waterfall_kwargs: Optional[dict] = None,\n",
    "    ):\n",
    "        \"\"\"Make a waterfall chart showing how each feature contributes\n",
    "        to the prediction for the input item.\n",
    "\n",
    "        Parameters:\n",
    "        - `item`: Input item, with the same shape and value meanings as\n",
    "        a single row from `self.X`\n",
    "        - `bar_num_formatter`: Bar label format specifier\n",
    "        - `tick_num_formatter`: Tick label format specifier\n",
    "        - `waterfall_kwargs`: kwargs to pass to `waterfall_chart.plot`\n",
    "        \"\"\"\n",
    "        if waterfall_kwargs is None:\n",
    "            waterfall_kwargs = {\n",
    "                \"sorted_value\": True,\n",
    "                \"threshold\": 0.01,\n",
    "                \"blue_color\": COLORS[\"blue\"],\n",
    "                \"green_color\": COLORS[\"green\"],\n",
    "                \"red_color\": COLORS[\"orange\"],\n",
    "            }\n",
    "        index = [\"int\"] + [\n",
    "            f\"{name}: {val:{tick_num_formatter}}\"\n",
    "            for name, val in zip(self.X.columns, item)\n",
    "        ]\n",
    "        vals = [self.model.intercept_] + list(self.model.coef_ * item)\n",
    "        waterfall_chart.plot(\n",
    "            index=index,\n",
    "            data=vals,\n",
    "            x_lab=\"Feature name and value\",\n",
    "            y_lab=\"Contribution to prediction\",\n",
    "            formatting=f\"{{:,{bar_num_formatter}}}\",\n",
    "            net_label=self.y.name,\n",
    "            **waterfall_kwargs,\n",
    "        )\n",
    "        return plt.gca()\n",
    "\n",
    "    def show_equation(\n",
    "        self,\n",
    "        intercept_formatter: str = \".2f\",\n",
    "        coef_formatter: str = \".2f\",\n",
    "    ):\n",
    "        \"\"\"Show linear model equation\n",
    "\n",
    "        Parameters:\n",
    "        - `intercept_formatter`: Intercept format specifier\n",
    "        - `coef_formatter`: Intercept format specifier\n",
    "        \"\"\"\n",
    "        return HTML(\n",
    "            _generate_linear_model_html(\n",
    "                intercept=self.model.intercept_,\n",
    "                coefs=self.model.coef_,\n",
    "                feature_names=self.X.columns,\n",
    "                target_name=self.y.name,\n",
    "                intercept_formatter=intercept_formatter,\n",
    "                coef_formatter=coef_formatter,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _LogRegInspector(_LinearInspector):\n",
    "    \"\"\"Logistic regression model inspector\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        is_binary = len(self.y.unique()) == 2\n",
    "        if is_binary:\n",
    "            self.show_equation = partial(_show_equation_bin, self)\n",
    "            update_wrapper(self.show_equation, _show_equation_bin)\n",
    "        else:\n",
    "            self.show_equation = partial(_show_equation_multiclass, self)\n",
    "            update_wrapper(self.show_equation, _show_equation_multiclass)\n",
    "\n",
    "    def plot_coefs_vs_hparam(self, hparam: str, vals: Sequence[float]) -> np.array:\n",
    "        \"\"\"Plot coefficient values against a hyperparameter\n",
    "\n",
    "        Parameters:\n",
    "        - `hparam`: Name of hyperparameter; must be an attribute of\n",
    "        `self.model`\n",
    "        - `vals`: Values of that hyperparameter to use\n",
    "        \"\"\"\n",
    "        current_val = getattr(self.model, hparam)\n",
    "        model = clone(self.model)\n",
    "        setattr(model, hparam, vals[-1])\n",
    "        column_order = model.fit(self.X, self.y).coef_[0].argsort()[::-1]\n",
    "        X = self.X.iloc[:, column_order]\n",
    "\n",
    "        coef_arrays = []\n",
    "        for val in vals:\n",
    "            setattr(model, hparam, val)\n",
    "            coef_arrays.append(model.fit(self.X, self.y).coef_)\n",
    "\n",
    "        num_target_vals = len(set(self.y))\n",
    "        if num_target_vals == 2:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(vals, [coefs[0] for coefs in coef_arrays])\n",
    "            axes = np.array(ax)[None]\n",
    "        else:\n",
    "            fig, axes = plt.subplots(\n",
    "                num_target_vals, 1, sharex=True, sharey=True, constrained_layout=True\n",
    "            )\n",
    "            for target_val_num in range(num_target_vals):\n",
    "                axes[target_val_num].plot(\n",
    "                    vals, [coefs[target_val_num] for coefs in coef_arrays]\n",
    "                )\n",
    "                axes[target_val_num].set_title(\n",
    "                    f\"y={sorted(set(self.y))[target_val_num]}\"\n",
    "                )\n",
    "        axes[0].set(xlabel=hparam, ylabel=\"Coefficient Value\")\n",
    "        for ax in axes:\n",
    "            ax.axvline(current_val, c=\"k\", label=\"current value\")\n",
    "        axes[0].legend(X.columns, bbox_to_anchor=(1.05, 1.0), loc=\"upper left\")\n",
    "        return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _show_equation_multiclass(\n",
    "    inspector,\n",
    "    intercept_formatter: str = \".2f\",\n",
    "    coef_formatter: str = \".2f\",\n",
    "):\n",
    "    \"\"\"Show multiclass logistic model equation\n",
    "\n",
    "    Parameters:\n",
    "    - `intercept_formatter`: Intercept format specifier\n",
    "    - `coef_formatter`: Intercept format specifier\n",
    "    \"\"\"\n",
    "    model_string = \"\"\n",
    "    for target_name, coefs, intercept in zip(\n",
    "        self.y.unique(), self.model.coef_, self.model.intercept_\n",
    "    ):\n",
    "        model_string += f\"\"\"\n",
    "                <p>\n",
    "                    {_generate_linear_model_html(\n",
    "                            intercept=intercept,\n",
    "                            coefs=coefs,\n",
    "                            feature_names=self.X.columns,\n",
    "                            target_name=f\"log-odds({self.y.name} = {target_name})\",\n",
    "                            intercept_formatter=intercept_formatter,\n",
    "                            coef_formatter=coef_formatter,\n",
    "                        )\n",
    "                    }\n",
    "                </p>\n",
    "            \"\"\"\n",
    "    return HTML(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _show_equation_bin(\n",
    "    inspector,\n",
    "    intercept_formatter: str = \".2f\",\n",
    "    coef_formatter: str = \".2f\",\n",
    "):\n",
    "    \"\"\"Show binary logistic model equation\n",
    "\n",
    "    Parameters:\n",
    "    - `intercept_formatter`: Intercept format specifier\n",
    "    - `coef_formatter`: Intercept format specifier\n",
    "    \"\"\"\n",
    "    return HTML(\n",
    "        _generate_linear_model_html(\n",
    "            intercept=inspector.model.intercept_[0],\n",
    "            coefs=inspector.model.coef_[0],\n",
    "            feature_names=inspector.X.columns,\n",
    "            target_name=f\"log-odds({inspector.y.name})\",\n",
    "            intercept_formatter=intercept_formatter,\n",
    "            coef_formatter=coef_formatter,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot1(\n",
    "    inspector: Inspector,\n",
    "    plot_data: bool = True,\n",
    "    line_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    ax: Optional[Axes] = None,\n",
    ") -> Axes:\n",
    "    \"\"\"Plot predictions from a regression or multiclass model with a\n",
    "    single input as a line\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `line_kwargs`: kwargs to pass to `ax.plot` for plotting\n",
    "    predictions\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _plot_preds(ax):\n",
    "        X_sorted = inspector.X.sort_values(inspector.X.columns[0])\n",
    "        ax.plot(\n",
    "            X_sorted.iloc[:, 0],\n",
    "            inspector.model.predict(X_sorted),\n",
    "            label=\"predictions\",\n",
    "            **line_kwargs,\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "    if line_kwargs is None:\n",
    "        line_kwargs = {}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {\"c\": \"k\", \"alpha\": 0.4}\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    if plot_data:\n",
    "        ax.scatter(inspector.X.iloc[:, 0], inspector.y, **scatter_kwargs)\n",
    "    ax = _plot_preds(ax)\n",
    "    ax.set(xlabel=inspector.X.columns[0], ylabel=inspector.y.name)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot1_bin(\n",
    "    inspector: Inspector,\n",
    "    thresh: Optional[float] = 0.5,\n",
    "    plot_data: bool = True,\n",
    "    prob_line_kwargs: Optional[dict] = None,\n",
    "    thresh_line_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    ax: Optional[Axes] = None,\n",
    ") -> Axes:\n",
    "    \"\"\"Plot predictions from a binary classification model that provides\n",
    "    probabilities and has a single input\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `thresh`: Threshold probability\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `prob_line_kwargs`: kwargs to pass to `ax.plot` for plotting\n",
    "    model probabilities\n",
    "    - `thresh_line_kwargs`: kwargs to pass to `ax.plot` for plotting\n",
    "    threshold\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _plot_probs(ax):\n",
    "        num_points = 100\n",
    "        X = np.linspace(inspector.X.min(), inspector.X.max(), num_points)\n",
    "        ax.plot(\n",
    "            X,\n",
    "            inspector.model.predict_proba(X)[:, 1],\n",
    "            label=\"probability\",\n",
    "            **prob_line_kwargs,\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    if prob_line_kwargs is None:\n",
    "        prob_line_kwargs = {}\n",
    "    if thresh_line_kwargs is None:\n",
    "        thresh_line_kwargs = {}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {\"c\": \"k\", \"alpha\": 0.4}\n",
    "\n",
    "    if plot_data:\n",
    "        ax.scatter(inspector.X.iloc[:, 0], inspector.y, **scatter_kwargs)\n",
    "    ax = _plot_probs(ax)\n",
    "    if thresh:\n",
    "        ax.plot(\n",
    "            inspector.X.iloc[:, 0],\n",
    "            thresh * np.ones(inspector.X.shape),\n",
    "            **thresh_line_kwargs,\n",
    "        )\n",
    "    ax.set(xlabel=inspector.X.columns[0], ylabel=inspector.y.name)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot2_regression(\n",
    "    inspector: Inspector,\n",
    "    plot_data: bool = True,\n",
    "    heatmap_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    tick_formatter: Optional[str] = \".2f\",\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot predictions from a model with two inputs as a heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `heatmap_kwargs`: kwargs to pass to `sns.heatmap` for plotting\n",
    "    predictions\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `tick_formatter`: Tick label format specifier\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _plot_preds(ax, **heatmap_kwargs):\n",
    "        x_grid = np.linspace(\n",
    "            inspector.X.iloc[:, 0].min(), inspector.X.iloc[:, 0].max(), 100\n",
    "        )\n",
    "        y_grid = np.linspace(\n",
    "            inspector.X.iloc[:, 1].max(), inspector.X.iloc[:, 1].min(), 100\n",
    "        )\n",
    "\n",
    "        preds = inspector.model.predict(\n",
    "            np.transpose([np.tile(x_grid, len(y_grid)), np.repeat(y_grid, len(x_grid))])\n",
    "        ).reshape(len(y_grid), len(x_grid))\n",
    "        preds = pd.DataFrame(preds, columns=x_grid, index=y_grid)\n",
    "        return sns.heatmap(\n",
    "            preds,\n",
    "            vmin=inspector.y.min(),\n",
    "            vmax=inspector.y.max(),\n",
    "            ax=ax,\n",
    "            **heatmap_kwargs,\n",
    "        )\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    if heatmap_kwargs is None:\n",
    "        heatmap_kwargs = {\"cmap\": \"viridis\"}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {\"cmap\": \"viridis\", \"edgecolor\": \"k\", \"zorder\": 999}\n",
    "\n",
    "    if plot_data:\n",
    "        ax = _plot_data_2d(X=inspector.X, y=inspector.y, ax=ax, **scatter_kwargs)\n",
    "    ax = _plot_preds(ax=ax, **heatmap_kwargs)\n",
    "    if tick_formatter is not None:\n",
    "        _format_ticks(ax=ax, formatter=tick_formatter)\n",
    "    ax.set(\n",
    "        xlabel=inspector.X.columns[0],\n",
    "        ylabel=inspector.X.columns[1],\n",
    "        title=inspector.y.name,\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot2_clas(\n",
    "    inspector: Inspector,\n",
    "    plot_data: bool = True,\n",
    "    heatmap_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    tick_formatter: Optional[str] = \".2f\",\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot data and predictions for classification model with two features\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `heatmap_kwargs`: kwargs to pass to `sns.heatmap` for plotting\n",
    "    predictions\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `tick_formatter`: Tick label format specifier\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _plot_preds(y_vals, label_to_num, ax, **scatter_kwargs):\n",
    "        num_points = 100\n",
    "        x_grid = np.linspace(\n",
    "            inspector.X.iloc[:, 0].min(), inspector.X.iloc[:, 0].max(), num_points\n",
    "        )\n",
    "        y_grid = np.linspace(\n",
    "            inspector.X.iloc[:, 1].max(), inspector.X.iloc[:, 1].min(), num_points\n",
    "        )\n",
    "\n",
    "        preds = inspector.model.predict(\n",
    "            np.transpose([np.tile(x_grid, len(y_grid)), np.repeat(y_grid, len(x_grid))])\n",
    "        ).reshape(len(y_grid), len(x_grid))\n",
    "        preds = pd.DataFrame(preds, columns=x_grid, index=y_grid)\n",
    "        for col in preds:\n",
    "            preds.loc[:, col] = preds.loc[:, col].map(label_to_num)\n",
    "        ax = sns.heatmap(preds.astype(int), **heatmap_kwargs)\n",
    "        return ax\n",
    "\n",
    "    def _set_colorbar(y_vals, ax):\n",
    "        colorbar = ax.collections[0].colorbar\n",
    "        r = colorbar.vmax - colorbar.vmin\n",
    "        colorbar.set_ticks(\n",
    "            [colorbar.vmin + r / len(y_vals) * (0.5 + i) for i in range(len(y_vals))]\n",
    "        )\n",
    "        colorbar.set_ticklabels(y_vals)\n",
    "        return colorbar\n",
    "\n",
    "    def _wash_out(ax):\n",
    "        rectangle = plt.Rectangle((0, 0), 100, 100, fc=\"w\", alpha=0.5)\n",
    "        ax.add_patch(rectangle)\n",
    "        return ax\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    if heatmap_kwargs is None:\n",
    "        heatmap_kwargs = {}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {\"edgecolor\": \"k\", \"zorder\": 999}\n",
    "\n",
    "    y_vals = inspector.y.unique()\n",
    "    label_to_num = {label: num for label, num in zip(y_vals, range(len(y_vals)))}\n",
    "    if heatmap_kwargs.get(\"cmap\") is None:\n",
    "        heatmap_kwargs[\"cmap\"] = sns.color_palette(None, len(y_vals))\n",
    "\n",
    "    ax = _plot_preds(y_vals, label_to_num, ax=ax, **heatmap_kwargs)\n",
    "    ax = _wash_out(ax)\n",
    "    colorbar = _set_colorbar(y_vals=y_vals, ax=ax)\n",
    "\n",
    "    if plot_data:\n",
    "        if scatter_kwargs.get(\"cmap\") is None:\n",
    "            scatter_kwargs[\"cmap\"] = colorbar.cmap\n",
    "        ax = _plot_data_2d(\n",
    "            X=inspector.X, y=inspector.y.map(label_to_num), ax=ax, **scatter_kwargs\n",
    "        )\n",
    "    _format_ticks(ax=ax, formatter=tick_formatter)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot_data_2d(X, y, ax, **scatter_kwargs):\n",
    "    X_normalized = MinMaxScaler().fit_transform(X) * 99\n",
    "    ax.scatter(\n",
    "        X_normalized[:, 0] + 0.5,\n",
    "        X_normalized[:, 1].max() - X_normalized[:, 1] + 0.5,\n",
    "        c=y,\n",
    "        **scatter_kwargs,\n",
    "    )\n",
    "    ax.set(xlabel=X.columns[0], ylabel=X.columns[1])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _format_ticks(ax, formatter):\n",
    "    labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels([f\"{float(label):{formatter}}\" for label in labels])\n",
    "\n",
    "    labels = [item.get_text() for item in ax.get_yticklabels()]\n",
    "    ax.set_yticklabels([f\"{float(label):{formatter}}\" for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot3d_regression(\n",
    "    inspector: Inspector,\n",
    "    plot_data: bool = True,\n",
    "    surf_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot predictions from a model with two inputs as a surface.\n",
    "\n",
    "    Best viewed with a tool such as https://github.com/matplotlib/ipympl\n",
    "    that supports rotating the output\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `surf_kwargs`: kwargs to pass to `ax.plot_surface` for plotting\n",
    "    predictions\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _plot_preds(ax):\n",
    "\n",
    "        x0_grid, x1_grid = _create_2d_grid(inspector.X)\n",
    "        ax.plot_surface(\n",
    "            x0_grid,\n",
    "            x1_grid,\n",
    "            _get_2d_grid_preds(inspector.model, x0_grid, x1_grid),\n",
    "            rstride=1,\n",
    "            cstride=1,\n",
    "            vmin=inspector.y.min(),\n",
    "            vmax=inspector.y.max(),\n",
    "            **surf_kwargs,\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    if surf_kwargs is None:\n",
    "        surf_kwargs = {\"alpha\": 0.4, \"cmap\": \"viridis\"}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {\"cmap\": \"viridis\"}\n",
    "    if plot_data:\n",
    "        ax.scatter(\n",
    "            inspector.X.iloc[:, 0],\n",
    "            inspector.X.iloc[:, 1],\n",
    "            inspector.y,\n",
    "            c=inspector.y,\n",
    "            **scatter_kwargs,\n",
    "        )\n",
    "    ax = _plot_preds(ax)\n",
    "    ax.set(\n",
    "        xlabel=inspector.X.columns[0],\n",
    "        ylabel=inspector.X.columns[1],\n",
    "        zlabel=inspector.y.name,\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot3d_multiclass(\n",
    "    inspector: Inspector,\n",
    "    plot_data: bool = True,\n",
    "    surf_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot predictions from a model with two inputs as a surface.\n",
    "\n",
    "    Best viewed with a tool such as https://github.com/matplotlib/ipympl\n",
    "    that supports rotating the output\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `plot_data`: Make a scatter plot of the data\n",
    "    - `surf_kwargs`: kwargs to pass to `ax.plot_surface` for plotting\n",
    "    predictions\n",
    "    - `scatter_kwargs`: kwargs to pass to `ax.scatter` for plotting data\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    if surf_kwargs is None:\n",
    "        surf_kwargs = {\"alpha\": 0.4, \"cmap\": \"viridis\"}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {}\n",
    "    y_vals = inspector.y.unique()\n",
    "    label_to_num = {label: num for label, num in zip(y_vals, range(len(y_vals)))}\n",
    "    y_int = inspector.y.map(label_to_num)\n",
    "\n",
    "    y_pred_int = pd.Series(inspector.model.predict(inspector.X)).map(label_to_num)\n",
    "    x0_grid, x1_grid = _create_2d_grid(inspector.X, num_points=20)\n",
    "    grid_preds = pd.DataFrame(\n",
    "        _get_2d_grid_preds(inspector.model, x0_grid, x1_grid)\n",
    "    ).applymap(lambda x: label_to_num[x])\n",
    "\n",
    "    for val in y_int.unique():\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            ax.plot_surface(\n",
    "                x0_grid,\n",
    "                x1_grid,\n",
    "                grid_preds[grid_preds == val],\n",
    "                rstride=1,\n",
    "                cstride=1,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        if plot_data:\n",
    "            ax.scatter(\n",
    "                inspector.X.iloc[:, 0].loc[y_int == val],\n",
    "                inspector.X.iloc[:, 1].loc[y_int == val],\n",
    "                y_pred_int.loc[y_int == val],\n",
    "                **scatter_kwargs,\n",
    "            )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot3d_bin(\n",
    "    inspector: Inspector,\n",
    "    thresh=0.5,\n",
    "    plot_prob: bool = True,\n",
    "    plot_thresh: bool = True,\n",
    "    plot_data: bool = True,\n",
    "    prob_surf_kwargs: Optional[dict] = None,\n",
    "    thresh_surf_kwargs: Optional[dict] = None,\n",
    "    scatter_kwargs: Optional[dict] = None,\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot data and predictions for binary classification model with 2\n",
    "    features in 3D\n",
    "\n",
    "    Best viewed with a tool such as https://github.com/matplotlib/ipympl\n",
    "    that supports rotating the output\n",
    "\n",
    "    Parameters:\n",
    "    - `inspector`: `Inspector` object\n",
    "    - `thresh`: Probability threshold for counting a prediction as\n",
    "    positive\n",
    "    - `plot_prob`: Whether to plot the model probabilities\n",
    "    - `plot_thresh`: Whether to plot a classification threshold\n",
    "    - `plot_data`: Whether to plot the data\n",
    "    - `prob_surf_kwargs`: kwargs to pass to the model probability\n",
    "    surface\n",
    "    - `thresh_surf_kwargs`: kwargs to pass to the threshold surface\n",
    "    - `scatter_kwargs`: kwargs to pass to the scatter plot of the data\n",
    "    - `ax`: Matplotlib `Axes` object. Plot will be added to this object\n",
    "    if provided; otherwise a new `Axes` object will be generated.\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_grid_probs():\n",
    "        return inspector.model.predict_proba(\n",
    "            np.hstack((x0_grid.reshape(-1, 1), x1_grid.reshape(-1, 1)))\n",
    "        )[:, 1].reshape(x0_grid.shape)\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    if prob_surf_kwargs is None:\n",
    "        prob_surf_kwargs = {\"alpha\": 0.4, \"cmap\": \"viridis\"}\n",
    "    if thresh_surf_kwargs is None:\n",
    "        thresh_surf_kwargs = {\"alpha\": 0.4, \"color\": \"k\"}\n",
    "    if scatter_kwargs is None:\n",
    "        scatter_kwargs = {}\n",
    "\n",
    "    x0_grid, x1_grid = _create_2d_grid(inspector.X)\n",
    "\n",
    "    if plot_prob:\n",
    "        ax.plot_surface(\n",
    "            x0_grid,\n",
    "            x1_grid,\n",
    "            _get_grid_probs(),\n",
    "            rstride=1,\n",
    "            cstride=1,\n",
    "            **prob_surf_kwargs,\n",
    "        )\n",
    "    if plot_data:\n",
    "        y_pred = inspector.model.predict_proba(inspector.X)[:, 1] > thresh\n",
    "        ax.scatter(\n",
    "            inspector.X.loc[y_pred == inspector.y].iloc[:, 0],\n",
    "            inspector.X.loc[y_pred == inspector.y].iloc[:, 1],\n",
    "            inspector.y.loc[y_pred == inspector.y],\n",
    "            **scatter_kwargs,\n",
    "            label=\"correct\",\n",
    "        )\n",
    "        ax.scatter(\n",
    "            inspector.X.loc[y_pred != inspector.y].iloc[:, 0],\n",
    "            inspector.X.loc[y_pred != inspector.y].iloc[:, 1],\n",
    "            inspector.y.loc[y_pred != inspector.y],\n",
    "            **scatter_kwargs,\n",
    "            label=\"incorrect\",\n",
    "        )\n",
    "        ax.legend()\n",
    "    if plot_thresh:\n",
    "        ax.plot_surface(\n",
    "            x0_grid,\n",
    "            x1_grid,\n",
    "            thresh * np.ones((len(x0_grid), len(x1_grid))),\n",
    "            rstride=1,\n",
    "            cstride=1,\n",
    "            **thresh_surf_kwargs,\n",
    "        )\n",
    "    ax.set(\n",
    "        xlabel=inspector.X.columns[0],\n",
    "        ylabel=inspector.X.columns[1],\n",
    "        zlabel=f\"{inspector.y.name} prediction\",\n",
    "    )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _create_2d_grid(X, num_points=20):\n",
    "    x0_grid = np.linspace(X.iloc[:, 0].min(), X.iloc[:, 0].max(), num_points)\n",
    "    x1_grid = np.linspace(X.iloc[:, 1].min(), X.iloc[:, 1].max(), num_points)\n",
    "    return np.meshgrid(x0_grid, x1_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_2d_grid_preds(model, x0_grid, x1_grid):\n",
    "    return model.predict(\n",
    "        np.hstack((x0_grid.reshape(-1, 1), x1_grid.reshape(-1, 1)))\n",
    "    ).reshape(x0_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _plot_waterfall_bin(\n",
    "    interp,\n",
    "    item: Union[pd.Series, np.array],\n",
    "    bar_num_formatter: str = \".1f\",\n",
    "    tick_num_formatter: str = \".2f\",\n",
    "    waterfall_kwargs: Optional[dict] = None,\n",
    "):\n",
    "    \"\"\"Make a waterfall chart showing how each feature contributes\n",
    "    to the prediction for the input item for a binary classification\n",
    "    model.\n",
    "\n",
    "    Parameters:\n",
    "    - `item`: Input item, with the same shape and value meanings as\n",
    "    a single row from `interp.X`\n",
    "    - `bar_num_formatter`: Bar label format specifier\n",
    "    - `tick_num_formatter`: Tick label format specifier\n",
    "    - ``waterfall_kwargs`: kwargs to pass to `waterfall_chart.plot`\n",
    "    \"\"\"\n",
    "    if waterfall_kwargs is None:\n",
    "        waterfall_kwargs = {\n",
    "            \"sorted_value\": True,\n",
    "            \"threshold\": 0.01,\n",
    "            \"blue_color\": COLORS[\"blue\"],\n",
    "            \"green_color\": COLORS[\"green\"],\n",
    "            \"red_color\": COLORS[\"orange\"],\n",
    "        }\n",
    "\n",
    "    index = [\"int\"] + [\n",
    "        f\"{name}: {val:{tick_num_formatter}}\"\n",
    "        for name, val in zip(interp.X.columns, item)\n",
    "    ]\n",
    "    vals = [interp.model.intercept_[0]] + list(interp.model.coef_[0] * item)\n",
    "    waterfall_chart.plot(\n",
    "        index=index,\n",
    "        data=vals,\n",
    "        x_lab=\"Feature name and value\",\n",
    "        y_lab=\"Contribution to log-odds\",\n",
    "        formatting=f\"{{:,{bar_num_formatter}}}\",\n",
    "        net_label=interp.y.name,\n",
    "        **waterfall_kwargs,\n",
    "    )\n",
    "    return plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _generate_linear_model_html(\n",
    "    intercept: float,\n",
    "    coefs: Sequence[float],\n",
    "    feature_names: Iterable[str],\n",
    "    target_name: str,\n",
    "    intercept_formatter: str = \".2f\",\n",
    "    coef_formatter: str = \".2f\",\n",
    "):\n",
    "    if len(coefs) != len(feature_names):\n",
    "        raise ValueError(\"len(coefs) != len(feature_cols)\")\n",
    "    model_string = f\"\"\"\n",
    "        <span style='color:{COLORS[\"pink\"]}'>{target_name}</span>\n",
    "        = <span style='color:{COLORS[\"orange\"]}'>{intercept:{intercept_formatter}}</span>\n",
    "    \"\"\"\n",
    "    for coef, feature_col in zip(coefs, feature_names):\n",
    "        model_string += f\"\"\"\n",
    "            <span style='color:{COLORS[\"green\"]}'>{\"+\" if coef >= 0 else \"-\"} {abs(coef):{coef_formatter}}</span>\n",
    "            * <span style='color:{COLORS[\"blue\"]}'>{feature_col}</span>\n",
    "        \"\"\"\n",
    "    return model_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-focus",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-celebrity",
   "metadata": {},
   "source": [
    "To use the functionality in this module, create an `Interpreter` object for a particular fitted scikit-learn model, feature DataFrame `X`, and target Series `y`. That object will have appropriate interpretation methods for the model type and data shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-darwin",
   "metadata": {},
   "source": [
    "## Universal Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-identification",
   "metadata": {},
   "source": [
    "Every `Inspector` object can run `plot_correlation` from the `model_inspector.explore` module on `pd.concat((self.X, self.y), axis=\"columns\")`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    RandomForestRegressor().fit(X_diabetes, y_diabetes), X_diabetes, y_diabetes\n",
    ")\n",
    "show_doc(inspector.plot_correlation, title_level=3)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8, 6))\n",
    "ax = inspector.plot_correlation(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-patrick",
   "metadata": {},
   "source": [
    "## Binary Classifier Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-gross",
   "metadata": {},
   "source": [
    "An `Inspector` for any binary classifier can run `calculate_metrics_by_thresh` from the `model_inspector.tune` module with `y_true=self.y` and `y_prob=self.model.predict(self.X)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X, y = X_cancer, y_cancer\n",
    "inspector = Inspector(RandomForestClassifier().fit(X, y), X, y)\n",
    "show_doc(inspector.calculate_metrics_by_thresh, title_level=3)\n",
    "\n",
    "\n",
    "def predict_true_if_prob_above_thresh(y_prob, thresh):\n",
    "    return np.where(y_prob[:, 1] > thresh, 1, 0)\n",
    "\n",
    "\n",
    "ax = (\n",
    "    inspector.calculate_metrics_by_thresh(\n",
    "        prob_to_pred=predict_true_if_prob_above_thresh,\n",
    "        metrics=[metrics.precision_score, metrics.recall_score, metrics.f1_score],\n",
    "    )\n",
    "    .iloc[:-1]\n",
    "    .plot(x=\"thresh\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-serial",
   "metadata": {},
   "source": [
    "## Linear Model Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-tucson",
   "metadata": {},
   "source": [
    "An `Inspector` for any model with an intercept and coefficients can show the model equation and plot coefficients against hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LinearRegression().fit(X_diabetes, y_diabetes), X_diabetes, y_diabetes\n",
    ")\n",
    "show_doc(inspector.show_equation, title_level=3, name=inspector.show_equation.__name__)\n",
    "\n",
    "inspector.show_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_cancer, y_cancer), X_cancer, y_cancer\n",
    ")\n",
    "show_doc(inspector.show_equation, title_level=3, name=\"show_equation\")\n",
    "\n",
    "inspector.show_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(Lasso().fit(X_diabetes, y_diabetes), X_diabetes, y_diabetes)\n",
    "show_doc(\n",
    "    inspector.plot_coefs_vs_hparam,\n",
    "    title_level=3,\n",
    "    name=inspector.plot_coefs_vs_hparam.__name__,\n",
    ")\n",
    "\n",
    "ax = inspector.plot_coefs_vs_hparam(\"alpha\", np.logspace(-2, 0.5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-society",
   "metadata": {},
   "source": [
    "## Linear Regression and Binary Classification Model Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-final",
   "metadata": {},
   "source": [
    "An `Inspector` for a regression or binary classification model with an intercept and coefficients can also generate a waterfall plot that shows how each feature contributes to a given prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LinearRegression().fit(X_diabetes, y_diabetes), X_diabetes, y_diabetes\n",
    ")\n",
    "show_doc(\n",
    "    inspector.plot_waterfall, title_level=3, name=inspector.plot_waterfall.__name__\n",
    ")\n",
    "\n",
    "ax = inspector.plot_waterfall(X_diabetes.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_cancer, y_cancer), X_cancer, y_cancer\n",
    ")\n",
    "show_doc(inspector.plot_waterfall, title_level=3, name=\"plot_waterfall\")\n",
    "\n",
    "ax = inspector.plot_waterfall(X_cancer.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-deadline",
   "metadata": {},
   "source": [
    "## One- Or Two-Feature Model Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-tyler",
   "metadata": {},
   "source": [
    "An `Inspector` for any model with one or two features has `.plot()` method, and one for any model with two features also has a `.plot3d()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-mills",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_cancer.iloc[:, [0]], y_cancer),\n",
    "    X_cancer.iloc[:, [0]],\n",
    "    y_cancer,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_cancer.iloc[:, :2], y_cancer),\n",
    "    X_cancer.iloc[:, :2],\n",
    "    y_cancer,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_cancer, y_cancer = sklearn.datasets.load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_cancer.iloc[:, :2], y_cancer),\n",
    "    X_cancer.iloc[:, :2],\n",
    "    y_cancer,\n",
    ")\n",
    "show_doc(inspector.plot3d, title_level=4, name=\"plot3d\")\n",
    "\n",
    "ax = inspector.plot3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-shakespeare",
   "metadata": {},
   "source": [
    "An interactive tool such as [ipyml](https://github.com/matplotlib/ipympl) makes it easier to see depth in these 3D plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\n",
    "    \"https://github.com/gsganden/model_inspector/blob/master/docs/regression_3d.mov?raw=true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-dayton",
   "metadata": {},
   "source": [
    "### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_iris, y_iris = sklearn.datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_iris.iloc[:, [0]], y_iris),\n",
    "    X_iris.iloc[:, [0]],\n",
    "    y_iris,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_iris, y_iris = sklearn.datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_iris.iloc[:, :2], y_iris),\n",
    "    X_iris.iloc[:, :2],\n",
    "    y_iris,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_iris, y_iris = sklearn.datasets.load_iris(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    LogisticRegression(max_iter=10_000).fit(X_iris.iloc[:, :2], y_iris),\n",
    "    X_iris.iloc[:, :2],\n",
    "    y_iris,\n",
    ")\n",
    "show_doc(inspector.plot3d, title_level=4, name=\"plot3d\")\n",
    "\n",
    "ax = inspector.plot3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-patch",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    RandomForestRegressor(max_depth=3).fit(X_diabetes.loc[:, [\"bmi\"]], y_diabetes),\n",
    "    X_diabetes.loc[:, [\"bmi\"]],\n",
    "    y_diabetes,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    RandomForestRegressor(max_depth=3).fit(\n",
    "        X_diabetes.loc[:, [\"bmi\", \"bp\"]], y_diabetes\n",
    "    ),\n",
    "    X_diabetes.loc[:, [\"bmi\", \"bp\"]],\n",
    "    y_diabetes,\n",
    ")\n",
    "show_doc(inspector.plot, title_level=4, name=\"plot\")\n",
    "\n",
    "ax = inspector.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_diabetes, y_diabetes = sklearn.datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "inspector = Inspector(\n",
    "    RandomForestRegressor(max_depth=3).fit(\n",
    "        X_diabetes.loc[:, [\"bmi\", \"bp\"]], y_diabetes\n",
    "    ),\n",
    "    X_diabetes.loc[:, [\"bmi\", \"bp\"]],\n",
    "    y_diabetes,\n",
    ")\n",
    "show_doc(inspector.plot3d, title_level=4, name=\"plot3d\")\n",
    "\n",
    "ax = inspector.plot3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
